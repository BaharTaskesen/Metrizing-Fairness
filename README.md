# Metrizing Fairness

NeurIPS 2021 Submission

## Anonymity Notice
This is an anonymous repository for NeurIPS 2021 review for "Metrizing Fairness".
Once the review process ends this repository will be deleted and replaced by a permanent repository. 
The anonymity policies of NeurIPS 2021 can be found at https://nips.cc/Conferences/2021/CallForPapers.

## Contents
- [Introduction](#introduction)
- [Quick Start](#quick-start)
- [Training](#training)
- [Numerical Results](#numerical-results)


## Introduction
We study supervised learning problems for predicting properties of individuals that belong to one of two demographic groups, and we seek fair predictors that result in similar output distributions for the groups. We propose a new fairness criterion characterized by a family of utility functions, whereby a predictor is viewed as fair if it generates the same expected utility of outputs for individuals of different groups with the same utility function. We term this new criterion societal fairness, and we show that it unifies several existing fairness notions. Moreover, we argue that unfairness is naturally measured by the distance of the output distributions of the two demographic groups with respect to an integral probability metric (IPM) generated by the family of utility functions. IPMs include popular probability metrics such as the Wasserstein, total variation, Kolmogorov or L^p-distances. To find fair estimators, we add the IPM associated with the desired fairness criterion to the objective function of the learning problem. We prove that this fairness-aware objective function admits unbiased gradient estimators if unfairness is measured by the squared L^2-distance or the energy distance. In this case the fair learning problem is susceptible to efficient stochastic gradient descent algorithms. Numerical experiments on real data show that our method systematically outperforms the state-of-the-art algorithms for fair learning.


## Quick Start
To clone the repository:
```
git clone https://github.com/Metric-Fairness-Authors/Metrizing-Fairness
cd Metrizing-Fairness
```

To install requirements:
```
pip install -r requirements.txt
```
## Training
To train the models in the paper, run this command:
```
python ./src/run.py
```

## Numerical results
The result shared in Figure 1, Table 3 are saved under ./results folder. Please refer to ./results-saved/zafar for results of Zafar et al., ./results-saved/FKDE for results of Cho et al., ./results-saved/NN_MMD_sinkhorn for results of Oneta et al. and ./results-saved/NN_energy for results of MFL (ours).

Plots in Figure 1 and results in Table 3 are obtained by ./prepare_results.ipynb. For each dataset please change the dataset variable to the desired.






